{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ca_funcs import get_network_entropies, make_table_walk, make_ca, make_glider\n",
    "from train_ca import initialize_model\n",
    "from utils import all_combinations\n",
    "\n",
    "from nni.compression.torch import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2\n",
    "D = (3, 3)\n",
    "ALL_INPUTS = all_combinations(M, D)\n",
    "RANDOM_INPUTS = np.random.choice([0, 1], (500, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CAs and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_CAs(rng=None):   \n",
    "    rng = rng or np.random.default_rng(0)\n",
    "    inputs = ALL_INPUTS\n",
    "    outputs = make_table_walk(len(ALL_INPUTS), rng=rng)\n",
    "    for o in outputs:\n",
    "        yield make_ca(inputs, o)\n",
    "\n",
    "def generate_CA_train_data(ca, height=10, width=10, n_samples=500, rng=None, noise=0.0):\n",
    "    rng = rng or np.random.default_rng(0)\n",
    "    X_train = torch.from_numpy(rng.choice([0, 1], (n_samples, height, width), p=[.5, .5])).float()\n",
    "    Y_train = ca(X_train).float()\n",
    "    foo = Y_train.detach().clone()\n",
    "    flat_Y_train = Y_train.view(-1)\n",
    "    flat_Y_indices = rng.choice(range(Y_train.numel()), size=int(Y_train.numel() * noise), replace=False)\n",
    "    flat_Y_train[flat_Y_indices] = 1 - flat_Y_train[flat_Y_indices]\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "for i, ca in enumerate(sample_CAs()):\n",
    "    X_test = torch.from_numpy(make_glider(10).reshape(1, 10, 10)).float()\n",
    "    Y_test = ca(X_test).float()\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.suptitle(i)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X_test[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(Y_test[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Output\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find entropy of the training CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ca_entropy(ca):        \n",
    "    inputs = torch.from_numpy(ALL_INPUTS)\n",
    "    outputs = ca(inputs)\n",
    "    output_counts = np.array(list(Counter(tuple(torch.reshape(o, [-1]).numpy()) for o in outputs).values()))\n",
    "    output_ps = output_counts / len(inputs)\n",
    "    return entropy(output_ps, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = [ca_entropy(a) for a in tqdm(sample_CAs(rng=np.random.default_rng(0)))]\n",
    "plt.plot(entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ca, rng=None, train_noise=0.0):\n",
    "    rng = rng or np.random.default_rng(0)\n",
    "\n",
    "    input_dims = [10, 10]\n",
    "    layer_dims = [100] + [100] * 11  # neighborhood conv + mlpconv layers\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    training_epochs = 100\n",
    "    samples = 500\n",
    "    batch_size = 10\n",
    "    num_batches = samples // batch_size\n",
    "    \n",
    "    def make_model(seed=0):\n",
    "        np.random.seed(seed)\n",
    "        torch.random.manual_seed(seed)\n",
    "\n",
    "        model = initialize_model(input_dims, layer_dims)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        display(model)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "\n",
    "        return model, optimizer\n",
    "\n",
    "    def learn_CA(model, optimizer):\n",
    "        losses = []\n",
    "        X_train, Y_train = generate_CA_train_data(ca, *input_dims, n_samples=samples, rng=rng, noise=train_noise)\n",
    "        if torch.cuda.is_available():\n",
    "            X_train = X_train.cuda()\n",
    "            Y_train = Y_train.cuda()\n",
    "\n",
    "        for _ in tqdm(range(training_epochs)):\n",
    "            batch_losses = []\n",
    "            for i in range(num_batches):\n",
    "                X_batch = X_train[i * batch_size : (i + 1) * batch_size]\n",
    "                Y_batch = Y_train[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                Y_pred = model(X_batch)\n",
    "                l = loss(Y_batch, Y_pred)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "                batch_losses.append(l.item())\n",
    "            losses.append(np.mean(batch_losses))\n",
    "        return losses\n",
    "    \n",
    "    model, optimizer = make_model()\n",
    "    losses = learn_CA(model, optimizer)\n",
    "    \n",
    "    return model, optimizer, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "model, optimizer, losses = train(\n",
    "    ca=list(sample_CAs(rng=rng))[24],\n",
    "    rng=rng,\n",
    "    train_noise=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.loglog();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.default_rng().choice([0, 1], size=100)\n",
    "# x = make_glider(10)\n",
    "X_test = torch.from_numpy(x.reshape(1, 10, 10)).float()\n",
    "Y_test = ca(X_test).float()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_test = X_test.cuda()\n",
    "Y_pred = model(X_test)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_test = X_test.cpu()\n",
    "    Y_pred = Y_pred.cpu()\n",
    "\n",
    "X_test = X_test.detach().numpy()\n",
    "Y_test = Y_test.detach().numpy()\n",
    "Y_pred = Y_pred.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(X_test[0])\n",
    "plt.axis('off')\n",
    "plt.title(\"Input\")\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(Y_test[0])\n",
    "plt.axis('off')\n",
    "plt.title(\"Expected Output\")\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(Y_pred[0], vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Observed Output\")\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow((Y_pred[0] - Y_test[0]) ** 2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Normalised Diff\")\n",
    "\n",
    "print('max loss:', ((Y_pred[0] - Y_test[0]) ** 2).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find model entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropies(model):\n",
    "    def get_activations(x_input):\n",
    "        activations = []\n",
    "        for m in model.children():\n",
    "            x_input = m(x_input)\n",
    "            activations.append(x_input)\n",
    "        return activations[1:-3:2]\n",
    "\n",
    "    X_test = np.pad(all_combinations(2, (3, 3)), [(0, 0), (3, 4), (3, 4)], 'wrap')\n",
    "    X_test = torch.from_numpy(X_test).float()\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        X_test = X_test.cuda()\n",
    "\n",
    "    res = [activation.cpu().detach().numpy() for activation in get_activations(X_test)]\n",
    "    layer_activations = np.array(res)\n",
    "    # Layer activations are floats, but to calculate entropy,\n",
    "    # we want to map activations to binary values,\n",
    "    # 1 if a given activation is >0, and 0 otherwise.\n",
    "    binary_activations = np.digitize(layer_activations, [0], right=True)\n",
    "    binary_activations = binary_activations.transpose(0, 1, -2, -1, 2) \\\n",
    "        .reshape(len(layer_dims), np.product(X_test.shape), layer_dims[0])\n",
    "    return get_network_entropies(binary_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_entropy(ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_entropies(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prune_model_and_test(model, Pruner, config):\n",
    "    model_copy = deepcopy(model)\n",
    "    pruner = Pruner(model_copy, config, optimizer=optimizer)\n",
    "    pruner.compress()\n",
    "    return model_copy\n",
    "\n",
    "def display_test(model):\n",
    "    x = make_glider(10)\n",
    "    X_test = torch.from_numpy(x.reshape(1, 10, 10)).float()\n",
    "    Y_test = ca(X_test).float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        X_test = X_test.cuda()\n",
    "    Y_pred = model(X_test)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        X_test = X_test.cpu()\n",
    "        Y_pred = Y_pred.cpu()\n",
    "\n",
    "    X_test = X_test.detach().numpy()\n",
    "    Y_test = Y_test.detach().numpy()\n",
    "    Y_pred = Y_pred.detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(X_test[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input\")\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(Y_test[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Expected Output\")\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(Y_pred[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Observed Output\")\n",
    "\n",
    "    plt.subplot(144)\n",
    "    plt.imshow((Y_pred[0] - Y_test[0]) ** 2)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Normalised Diff\")\n",
    "\n",
    "    print('max loss:', ((Y_pred[0] - Y_test[0]) ** 2).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_list = [{ 'sparsity': 0.1, 'op_types': ['default'] }]\n",
    "m = prune_model_and_test(model, LevelPruner, config_list)\n",
    "display_test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPGM Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_list = [{ 'sparsity': 0.1, 'op_types': ['Conv2d'] }]\n",
    "m = prune_model_and_test(model, FPGMPruner, config_list)\n",
    "display_test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_list = [{ 'sparsity': 0.1, 'op_types': ['Conv2d'] }]\n",
    "m = prune_model_and_test(model, L1FilterPruner, config_list)\n",
    "display_test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_list = [{ 'sparsity': 0.1, 'op_types': ['Conv2d'] }]\n",
    "m = prune_model_and_test(model, L2FilterPruner, config_list)\n",
    "display_test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotteryTicket Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_list = [{\n",
    "    'prune_iterations': 50,\n",
    "    'sparsity': 0.1,\n",
    "    'op_types': ['default']\n",
    "}]\n",
    "m = prune_model_and_test(model, LotteryTicketPruner, config_list)\n",
    "display_test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMC Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmc_complexity(P, N):\n",
    "    P = np.array(P)\n",
    "    P = P / P.sum()\n",
    "    H = entropy(P, base=2)\n",
    "    \n",
    "    if N <= np.finfo(P.dtype).max:\n",
    "        uniform_ps = np.full(len(P), 1.0 / N)\n",
    "        D = np.sum((P - uniform_ps) ** 2) + (N - len(P)) * (1.0 / N)**2\n",
    "    else:\n",
    "        # assuming N >> len(P) >= 1 >= P, so that len(P)/N, 1/N and P/N are negligible\n",
    "        D = np.sum(P ** 2)\n",
    "        \n",
    "    return H * D\n",
    "\n",
    "def ca_lmc(ca, m=M, d=D):  \n",
    "    inputs = torch.from_numpy(ALL_INPUTS)\n",
    "    outputs = ca(inputs)\n",
    "    output_counts = np.array(list(Counter(tuple(torch.reshape(o, [-1]).numpy()) for o in outputs).values()))\n",
    "    output_ps = output_counts / len(inputs)\n",
    "    return lmc_complexity(output_ps, m ** np.product(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmcs = [ca_lmc(a) for a in tqdm(sample_CAs(np.random.default_rng(0)))]\n",
    "plt.plot(lmcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_lmcs(layers_samples_neurons):\n",
    "    neuron_lmcs_by_layer = []\n",
    "    layer_lmcs = []\n",
    "    \n",
    "    layer_count = layers_samples_neurons.shape[0]\n",
    "    neuron_count = layers_samples_neurons.shape[2]\n",
    "    \n",
    "    for l in layers_samples_neurons:\n",
    "        neuron_ps = l.mean(axis=0)\n",
    "        neuron_lmcs_by_layer.append(np.array([lmc_complexity([p, 1-p], 2) for p in neuron_ps]))\n",
    "        \n",
    "        layer_patterns = (tuple(sample) for sample in l)\n",
    "        layer_pattern_counts = list(Counter(layer_patterns).values())\n",
    "        layer_lmcs.append(lmc_complexity(layer_pattern_counts, 2 ** neuron_count))\n",
    "        \n",
    "    network_patterns = (tuple(sample.ravel()) for sample in layers_samples_neurons.swapaxes(0, 1))\n",
    "    network_pattern_counts = list(Counter(network_patterns).values())\n",
    "    network_lmc = lmc_complexity(network_pattern_counts, 2 ** (layer_count * neuron_count))\n",
    "    \n",
    "    return network_lmc, layer_lmcs, neuron_lmcs_by_layer\n",
    "\n",
    "def model_lmc(model):\n",
    "    def get_activations(x_input):\n",
    "        activations = []\n",
    "        for m in model.children():\n",
    "            x_input = m(x_input)\n",
    "            activations.append(x_input)\n",
    "        return activations[1:-3:2]\n",
    "\n",
    "    X_test = np.pad(all_combinations(2, (3, 3)), [(0, 0), (3, 4), (3, 4)], 'wrap')\n",
    "    X_test = torch.from_numpy(X_test).float()\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        X_test = X_test.cuda()\n",
    "\n",
    "    res = [activation.cpu().detach().numpy() for activation in get_activations(X_test)]\n",
    "    layer_activations = np.array(res)\n",
    "    # Layer activations are floats, but to calculate lmc complexity,\n",
    "    # we want to map activations to binary values,\n",
    "    # 1 if a given activation is >0, and 0 otherwise.\n",
    "    binary_activations = np.digitize(layer_activations, [0], right=True)\n",
    "    binary_activations = binary_activations.transpose(0, 1, -2, -1, 2) \\\n",
    "        .reshape(len(layer_dims), np.product(X_test.shape), layer_dims[0])\n",
    "    return get_network_lmcs(binary_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_lmc(ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lmc(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas = np.array([ca for ca in sample_CAs(rng=np.random.default_rng(0))])\n",
    "ca_entropies = np.array([ca_entropy(ca) for ca in cas])\n",
    "ca_lmcs = np.array([ca_lmc(ca) for ca in cas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = np.r_[0:8:2, 8:128:16, 128:256:32]\n",
    "i_test = np.sort(np.r_[i_test, 511 - i_test, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(ca_entropies)\n",
    "plt.plot(i_test, ca_entropies[i_test], 'r.')\n",
    "plt.subplot(212)\n",
    "plt.plot(ca_lmcs)\n",
    "plt.plot(i_test, ca_lmcs[i_test], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
