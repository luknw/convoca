{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ca_funcs import make_glider\n",
    "\n",
    "from nni.compression.torch import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paper_replication as pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CAs and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ca in enumerate(pr.sample_CAs(rng=np.random.default_rng(0))):\n",
    "    X_test = torch.from_numpy(make_glider(10).reshape(1, 10, 10)).float()\n",
    "    Y_test = ca(X_test).float()\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.suptitle(i)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X_test[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(Y_test[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Output\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find entropy of the training CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = [pr.ca_entropy(a) for a in tqdm(pr.sample_CAs(rng=np.random.default_rng(0)))]\n",
    "plt.plot(entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "ca = list(pr.sample_CAs(rng=rng))[24]\n",
    "layer_dims = [100] + [100] * 11  # neighborhood conv + mlpconv layers\n",
    "\n",
    "model, optimizer, losses = pr.train(\n",
    "    100,\n",
    "    ca,\n",
    "    layer_dims,\n",
    "    rng,\n",
    "    train_noise=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.loglog();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.default_rng().choice([0, 1], size=100)\n",
    "# x = make_glider(10)\n",
    "X_test = torch.from_numpy(x.reshape(1, 10, 10)).float()\n",
    "Y_test = ca(X_test).float()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_test = X_test.cuda()\n",
    "Y_pred = model(X_test)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_test = X_test.cpu()\n",
    "    Y_pred = Y_pred.cpu()\n",
    "\n",
    "X_test = X_test.detach().numpy()\n",
    "Y_test = Y_test.detach().numpy()\n",
    "Y_pred = Y_pred.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(X_test[0])\n",
    "plt.axis('off')\n",
    "plt.title(\"Input\")\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(Y_test[0])\n",
    "plt.axis('off')\n",
    "plt.title(\"Expected Output\")\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(Y_pred[0], vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title(\"Observed Output\")\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow((Y_pred[0] - Y_test[0]) ** 2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Normalised Diff\")\n",
    "\n",
    "print('max loss:', ((Y_pred[0] - Y_test[0]) ** 2).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find model entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.ca_entropy(ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.calculate_entropies(model, layer_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list = list(pr.sample_CAs(rng=np.random.default_rng(0)))\n",
    "sparsity_values = [0.1, 0.25, 0.33, 0.5, 0.66, 0.75, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = [pr.test_model(model, ca) for i, ca in enumerate(ca_list)]\n",
    "plt.plot(res)\n",
    "    \n",
    "for sparsity in tqdm(sparsity_values):\n",
    "    config_list = [{ 'sparsity': sparsity, 'op_types': ['default'] }]\n",
    "    m = pr.prune_model_and_test(model, optimizer, LevelPruner, config_list)\n",
    "    res = [pr.test_model(m, ca) for i, ca in enumerate(ca_list)]\n",
    "    plt.plot(res)\n",
    "    \n",
    "plt.title('Level Pruner - Loss - L2 metric')\n",
    "plt.legend([0.0] + sparsity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPGM Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = [pr.test_model(model, ca) for i, ca in enumerate(ca_list)]\n",
    "plt.plot(res)\n",
    "\n",
    "for sparsity in tqdm(sparsity_values):\n",
    "    config_list = [{ 'sparsity': sparsity, 'op_types': ['Conv2d'] }]\n",
    "    m = pr.prune_model_and_test(model, optimizer, FPGMPruner, config_list)\n",
    "    res = [pr.test_model(m, ca) for i, ca in enumerate(ca_list)]\n",
    "    plt.plot(res)\n",
    "    \n",
    "plt.title('FPGM Pruner - Loss - L2 metric')\n",
    "plt.legend([0.0] + sparsity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = [pr.test_model(model, ca) for i, ca in enumerate(ca_list)]\n",
    "plt.plot(res)\n",
    "\n",
    "for sparsity in tqdm(sparsity_values):\n",
    "    config_list = [{ 'sparsity': sparsity, 'op_types': ['Conv2d'] }]\n",
    "    m = pr.prune_model_and_test(model, optimizer, L1FilterPruner, config_list)\n",
    "    res = [pr.test_model(m, ca) for i, ca in enumerate(ca_list)]\n",
    "    plt.plot(res)\n",
    "    \n",
    "plt.title('L1 Pruner - Loss - L2 metric')\n",
    "plt.legend([0.0] + sparsity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = [pr.test_model(model, ca) for i, ca in enumerate(ca_list)]\n",
    "plt.plot(res)\n",
    "\n",
    "for sparsity in tqdm(sparsity_values):\n",
    "    config_list = [{ 'sparsity': sparsity, 'op_types': ['Conv2d'] }]\n",
    "    m = pr.prune_model_and_test(model, optimizer, L2FilterPruner, config_list)\n",
    "    res = [pr.test_model(m, ca) for i, ca in enumerate(ca_list)]\n",
    "    plt.plot(res)\n",
    "    \n",
    "plt.title('L2 Pruner - Loss - L2 metric')\n",
    "plt.legend([0.0] + sparsity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotteryTicket Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = [pr.test_model(model, ca) for i, ca in enumerate(ca_list)]\n",
    "plt.plot(res)\n",
    "\n",
    "for sparsity in tqdm(sparsity_values):\n",
    "    config_list = [{\n",
    "        'prune_iterations': 50,\n",
    "        'sparsity': sparsity,\n",
    "        'op_types': ['default']\n",
    "    }]\n",
    "    m = pr.prune_model_and_test(model, optimizer, LotteryTicketPruner, config_list)\n",
    "    res = [pr.test_model(m, ca) for i, ca in enumerate(ca_list)]\n",
    "    plt.plot(res)\n",
    "    \n",
    "plt.title('LotteryTicket Pruner - Loss - L2 metric')\n",
    "plt.legend([0.0] + sparsity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMC Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmcs = [pr.ca_lmc(a) for a in tqdm(pr.sample_CAs(np.random.default_rng(0)))]\n",
    "plt.plot(lmcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.ca_lmc(ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.model_lmc(model, layer_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas = np.array([ca for ca in pr.sample_CAs(rng=np.random.default_rng(0))])\n",
    "ca_entropies = np.array([pr.ca_entropy(ca) for ca in cas])\n",
    "ca_lmcs = np.array([pr.ca_lmc(ca) for ca in cas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = np.r_[0:8:2, 8:128:16, 128:256:32]\n",
    "i_test = np.sort(np.r_[i_test, 511 - i_test, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(ca_entropies)\n",
    "plt.plot(i_test, ca_entropies[i_test], 'r.')\n",
    "plt.subplot(212)\n",
    "plt.plot(ca_lmcs)\n",
    "plt.plot(i_test, ca_lmcs[i_test], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}