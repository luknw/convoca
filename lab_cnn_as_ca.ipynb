{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network as Cellular Automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: https://doi.org/10.1103/PhysRevE.100.032402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quoting Wikipedia:\n",
    "\n",
    "> A cellular automaton consists of a regular grid of cells, each in one of a finite number of states, such as on and off [...]. The grid can be in any finite number of dimensions. For each cell, a set of cells called its neighbourhood is defined relative to the specified cell. An initial state (time t = 0) is selected by assigning a state for each cell. A new generation is created (advancing t by 1), according to some fixed rule (generally, a mathematical function) that determines the new state of each cell in terms of the current state of the cell and the states of the cells in its neighbourhood. Typically, the rule for updating the state of cells is the same for each cell and does not change over time, and is applied to the whole grid simultaneously [...]\n",
    ">\n",
    "> <cite>https://en.wikipedia.org/wiki/Cellular_automaton</cite>\n",
    "\n",
    "The important thing here is that cellular automatons are local, i.e. the next state of each cell depends only on the cells in its neighbourhood. This principle of locality is also a basis for applying convolutional filters, which combine information from a single part of the image at a time. Expanding on this similarity, we can ponder whether cellular automatons and convolutional neural networks have more things in common. Let's check this out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAs and convolutions in plain Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a few simple CAs to learn the techniques we'll be using further. The CAs will:\n",
    "* be defined on a square grid\n",
    "* have 2 states - so called binary CA, the states are usually called dead (0) and alive (1)\n",
    "* use Moore neighbourhood - a square of 3 by 3 cells with a cell of reference in the centre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from itertools import count\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['figure.figsize'] = (7, 7)\n",
    "\n",
    "def plot_state(state):\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(state)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "\n",
    "def run_ca(ca, size=(100, 100), p_alive=0.5, iters=None):\n",
    "    iters = range(iters) if iters else count()\n",
    "    \n",
    "    state = np.random.choice([0, 1], size=size, p=[1-p_alive, p_alive])\n",
    "    m, n = state.shape\n",
    "    state[m//2, n//2] = 1 if p_alive > 0 else 0 # ensure at least 1 living cell\n",
    "    plot_state(state)\n",
    "    for _ in iters:\n",
    "        time.sleep(0.1)\n",
    "        state = ca(state)\n",
    "        plot_state(state) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Rule-based CA\n",
    "The simplest automaton can be defined by pattern-matching rules for each possible input. No big deal, we just need to pay attention to boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(a):\n",
    "    \"\"\"\n",
    "    Convert array to a tuple for use as a dictionary key.\n",
    "    \"\"\"\n",
    "    return tuple(np.array(a).ravel())\n",
    "\n",
    "def triangles(state):\n",
    "    survives = set(k(s) for s in (\n",
    "        [[0, 0, 1], [0, 0, 0], [0, 0, 0]],\n",
    "        [[0, 0, 0], [0, 0, 0], [0, 0, 1]],\n",
    "        [[0, 0, 0], [1, 0, 0], [0, 0, 0]],\n",
    "    ))\n",
    "    \n",
    "    new_state = np.zeros_like(state)\n",
    "    \n",
    "    # TODO: We want to have a state grid that's _wrapped_ around,\n",
    "    # left to right and top to bottom, so that CA rules\n",
    "    # can be safely applied at the boundary.\n",
    "    # Hint: use np.pad with the right mode.\n",
    "    state_pad = np.pad(state, 1, 'wrap')\n",
    "    \n",
    "    for i in range(state.shape[0]):\n",
    "        for j in range(state.shape[1]):\n",
    "            if k(state_pad[i:i+3, j:j+3]) in survives:\n",
    "                new_state[i][j] = 1\n",
    "    \n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ca(triangles, p_alive=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Convolution\n",
    "Let's build a simple convolution which sums the numbers in a 3 by 3 square just to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "def conv_sum_neighbours(a):\n",
    "    # TODO: Define a convolution kernel that will sum all values\n",
    "    # inside a 3x3 block apart from the center square.\n",
    "    # Hint: the kernel will be a 3x3 array with 1s and 0s in the right places.\n",
    "    kernel = np.pad([[0]], 1, constant_values=1)\n",
    "    return convolve2d(a, kernel, mode='valid')\n",
    "\n",
    "# test inputs have size 3x3 just to make things simple\n",
    "def conv_test():\n",
    "    x = np.arange(1, 10).reshape(3, 3)\n",
    "    print(x)\n",
    "    print(x.sum(), conv_sum_neighbours(x))\n",
    "    \n",
    "    eq = []\n",
    "    for i in range(10):\n",
    "        x = np.random.rand(3, 3)\n",
    "        eq.append(np.isclose(conv_sum_neighbours(x), x.sum() - x[1, 1]))\n",
    "    print(all(eq))\n",
    "\n",
    "conv_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Totalistic CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Totalistic CAs don't care about layout of cells in a neighbourhood, they just compute some neighbourhood statistic like a number of living cells. As we already know, the sum of values in the neighbouring cells is a perfect use case for a convolution!\n",
    "\n",
    "The convolution will be computed for all cells at once using arcane knowledge of the fast Fourier transform. This also has a nice side effect that we get wrapped boundaries for free. It's not that important how this FFT works, you can treat it as a black box. The important bit is that we use a convolution to implement a CA transition function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from: https://github.com/thearn/game-of-life\n",
    "from numpy.fft import fft2, ifft2\n",
    "\n",
    "def fft_convolve2d(x, y):\n",
    "    \"\"\"\n",
    "    2D convolution, using FFT\n",
    "    \"\"\"\n",
    "    fr = fft2(x)\n",
    "    fr2 = fft2(np.flipud(np.fliplr(y)))\n",
    "    m, n = fr.shape\n",
    "    cc = np.real(ifft2(fr*fr2))\n",
    "    cc = np.roll(cc, - int(m / 2) + 1, axis=0)\n",
    "    cc = np.roll(cc, - int(n / 2) + 1, axis=1)\n",
    "    return cc.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Conway's game of Life\n",
    "The most famous cellular automaton that exhibits complex behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conway(state):\n",
    "    kernel = np.zeros_like(state)\n",
    "    m, n = kernel.shape\n",
    "    \n",
    "    # TODO: define a 3x3 convolution kernel that will count living neighbours (state := 1) of the cell\n",
    "    kernel[m//2-1 : m//2+2, n//2-1 : n//2+2] = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "\n",
    "    # 2d table with counts of living neighbours for each corresponding cell from the state\n",
    "    neighbours_alive = fft_convolve2d(state, kernel)\n",
    "    \n",
    "    new_state = np.zeros_like(neighbours_alive)\n",
    "    \n",
    "    born = [3]\n",
    "    survives = [2, 3]\n",
    "    # TODO: place born & survives arrays in the right places\n",
    "    # states: 0 - dead, 1 - alive\n",
    "    new_state[np.where((state == 0) & np.isin(neighbours_alive, born))] = 1\n",
    "    new_state[np.where((state == 1) & np.isin(neighbours_alive, survives))] = 1\n",
    "\n",
    "    return new_state   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ca(conway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day and night automaton\n",
    "We've seen the `triangles` CA which behaves orderly up to a point, but then quite reliably transforms into a random mess and also the `conway` CA that can have runs of varying length and complexity. What determines the CA complexity? Let's compare a few other automatons with rules that differ only slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sum_ca(born, survives):\n",
    "    def ca(state):\n",
    "        kernel = np.zeros_like(state)\n",
    "        m, n = kernel.shape\n",
    "        kernel[m//2-1 : m//2+2, n//2-1 : n//2+2] = np.pad([[0]], 1, constant_values=1)\n",
    "\n",
    "        neighbours_alive = fft_convolve2d(state, kernel)\n",
    "\n",
    "        new_state = np.zeros_like(neighbours_alive)\n",
    "        new_state[np.where((state == 0) & np.isin(neighbours_alive, born))] = 1\n",
    "        new_state[np.where((state == 1) & np.isin(neighbours_alive, survives))] = 1\n",
    "\n",
    "        return new_state\n",
    "    return ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: CA comparison\n",
    "Run each of the following CAs and just observe the results. The first CA is called \"day and night\", becuase it exhibits symmetry between dead and alive states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_and_night = [\n",
    "    (f'day_and_night_{i}', n_sum_ca(born, survives))\n",
    "    for i, (born, survives)\n",
    "    in enumerate([\n",
    "        ([3, 6, 7, 8], [3, 4, 6, 7, 8]),\n",
    "        ([3, 4, 6, 7, 8], [3, 4, 6, 7, 8]),\n",
    "        ([3, 6, 7, 8], [3, 6, 7, 8]),\n",
    "        ([3, 4, 6, 7, 8], [3, 6, 7, 8])\n",
    "    ])\n",
    "]\n",
    "\n",
    "def run(i, **kwargs):\n",
    "    name, ca = day_and_night[i]\n",
    "    run_ca(ca, **kwargs)\n",
    "    print(name, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(0, iters=100, p_alive=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(1, iters=100, p_alive=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(2, iters=100, p_alive=0.875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(3, iters=30, p_alive=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(3, iters=100, p_alive=0.78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(3, iters=100, p_alive=0.22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, modifying the rules slightly can change the automaton behaviour a lot. In case of our automata, we could probably start building intuition about the outcomes, but the symmetry we encountered is just the matter of this specific \"day and night\" automaton. To make matters worse, the last example shows that the behaviour can vary based on the input distribution... and we're only looking at totalistic automata. Things get even more unpredictable for rule-based CAs.\n",
    "\n",
    "How to quantify this? How to quantify the complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wolfram classification & entropy\n",
    "Approaching the problem differently, we could try to describe automatons qualitatively, by pointing out the kinds of outcomes they produce. The most prominent classification was proposed by Wolfram:\n",
    "\n",
    "### Wolfram classification\n",
    "* Class 1: Nearly all initial patterns evolve quickly into a stable, homogeneous state. Any randomness in the initial pattern disappears.\n",
    "* Class 2: Nearly all initial patterns evolve quickly into stable or oscillating structures. Some of the randomness in the initial pattern may filter out, but some remains. Local changes to the initial pattern tend to remain local.\n",
    "* Class 3: Nearly all initial patterns evolve in a pseudo-random or chaotic manner. Any stable structures that appear are quickly destroyed by the surrounding noise. Local changes to the initial pattern tend to spread indefinitely.\n",
    "* Class 4: Nearly all initial patterns evolve into structures that interact in complex and interesting ways, with the formation of local structures that are able to survive for long periods of time.\n",
    "\n",
    "The descriptions are from: https://en.wikipedia.org/wiki/Cellular_automaton#Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "To quantify the automaton complexity, we can look at all possible automaton input neighbourhoods, apply the CA transformation to each one of them, each time producing as output a new state for a single cell. $\\lambda$ is defined as the ratio of such output cells that are alive. $\\lambda = 0$ when all outputs are dead, $\\lambda = 1$ when all are alive, and $\\lambda = 0.5$ when the two outcomes are balanced. A rule of thumb is that the closer $\\lambda$ is to 0.5, the greater the automaton complexity and the higher Wolfram's class.\n",
    "\n",
    "We won't use $\\lambda$ directly, however we'll use a metric that's correlated with it: the automaton entropy. Let's assume we apply a CA transition once to an input that has a uniform distribution of all possible neighbourhoods. After the one CA transition, for each possible neighbourhood $\\sigma$ we calculate its probability of appearing in the output $p_\\sigma$ and calculate the entropy of their distribution. The number we get is called automaton entropy:\n",
    "\n",
    "$$H_{ca} = -\\sum_{\\sigma} p_\\sigma \\log_2{p_\\sigma}$$\n",
    "\n",
    "For binary automata (2 states) with Moore neighborhood (9 cells), the entropy ranges from 0 (all inputs map to the same output neighbourhood) to 9 (uniform neighbourhood distribution in output). Let's find the value of entropy for the automata we already know. Since synthesising an image with a uniform input distribution is complicated, we'll approximate it by applying the CA to all possible input neighbourhoods wrapped around one by one and then adding up the counts of output neighbourhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Calculating automaton entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "def all_combinations(m, d):\n",
    "    '''\n",
    "    Make an array of all d dimensional inputs\n",
    "    consisting of m possible values\n",
    "    '''\n",
    "    \n",
    "    sq = int(np.sqrt(d))\n",
    "    \n",
    "    indices = np.tile(np.array([np.arange(m)]).T, d)\n",
    "\n",
    "    all_combos = list(product(*list(indices.T)))\n",
    "    out = np.reshape(np.array(all_combos), (-1, sq, sq))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def simple_ca_entropy(ca):\n",
    "    # TODO: Provide the right parameters for the functions.\n",
    "    outputs = Counter(k(ca(c)) for c in all_combinations(2, 9))\n",
    "    return entropy(list(outputs.values()), base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('triangles', simple_ca_entropy(triangles))\n",
    "print('conway', simple_ca_entropy(conway))\n",
    "for name, ca in day_and_night:\n",
    "    print(name, simple_ca_entropy(ca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN as CA\n",
    "### Network model\n",
    "### Basic training\n",
    "### Experiments\n",
    "#### CA perturbations\n",
    "#### Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
